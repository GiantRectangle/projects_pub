{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best tuned settings:\n",
    "\n",
    "    *  R2 for test grs data: 0.741831331625251\n",
    "    \n",
    "    *  negMedAE for test grs data: -4331.783660283572\n",
    "\n",
    "    *  R2 for test gcs data: 0.6413601516047931\n",
    "\n",
    "    *  negMedAE for test gcs data: -9864.76437192755"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SwanS\\Anaconda3\\envs\\grs_fit\\lib\\site-packages\\tpot\\builtins\\__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    }
   ],
   "source": [
    "from helpers import utils\n",
    "from os.path import join, dirname\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pickle\n",
    "from snowflake import connector\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RepeatedKFold\n",
    "from sklearn.preprocessing import Normalizer, QuantileTransformer, RobustScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor\n",
    "from tpot.builtins import StackingEstimator\n",
    "from tpot.export_utils import set_param_recursive\n",
    "from sklearn.metrics import r2_score, make_scorer\n",
    "\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "# get environment variables\n",
    "dotenv_path = join(dirname('streamlit_grs_fit\\\\app\\\\'), '.env')\n",
    "load_dotenv(dotenv_path)\n",
    "SF_ACCOUNT = os.getenv('SF_ACCOUNT')\n",
    "SF_USER = os.getenv('SF_USER')\n",
    "SF_PASSWORD = os.getenv('SF_PASSWORD')\n",
    "SF_ROLE = os.getenv('SF_ROLE')\n",
    "SF_WAREHOUSE = os.getenv('SF_WAREHOUSE')\n",
    "SF_DATABASE = os.getenv('SF_DATABASE')\n",
    "SF_SCHEMA = os.getenv('SF_SCHEMA')\n",
    "\n",
    "def load_data(query):\n",
    "    conn = connector.connect(\n",
    "        user = SF_USER\n",
    "        ,password = SF_PASSWORD\n",
    "        ,account = SF_ACCOUNT\n",
    "        ,warehouse = SF_WAREHOUSE\n",
    "        ,database = SF_DATABASE\n",
    "        ,schema = SF_SCHEMA\n",
    "        ,role = SF_ROLE\n",
    "    )\n",
    "    cur = conn.cursor()\n",
    "    df_data = cur.execute(query).fetch_pandas_all()\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'select '+\\\n",
    "            'JOB'+\\\n",
    "            ',DIRECT_COST'+\\\n",
    "            ',DIV_00_DIRECT_COST'+\\\n",
    "            ',DIV_01_DIRECT_COST'+\\\n",
    "            ',DIV_02_DIRECT_COST'+\\\n",
    "            ',DIV_03_DIRECT_COST'+\\\n",
    "            ',DIV_04_DIRECT_COST'+\\\n",
    "            ',DIV_05_DIRECT_COST'+\\\n",
    "            ',DIV_06_DIRECT_COST'+\\\n",
    "            ',DIV_07_DIRECT_COST'+\\\n",
    "            ',DIV_08_DIRECT_COST'+\\\n",
    "            ',DIV_09_DIRECT_COST'+\\\n",
    "            ',DIV_10_DIRECT_COST'+\\\n",
    "            ',DIV_11_DIRECT_COST'+\\\n",
    "            ',DIV_12_DIRECT_COST'+\\\n",
    "            ',DIV_13_DIRECT_COST'+\\\n",
    "            ',DIV_14_DIRECT_COST'+\\\n",
    "            ',DIV_15_DIRECT_COST'+\\\n",
    "            ',DIV_16_DIRECT_COST'+\\\n",
    "            ',DIV_17_DIRECT_COST'+\\\n",
    "            ',DIV_18_DIRECT_COST'+\\\n",
    "            ',DIV_19_DIRECT_COST'+\\\n",
    "            ',DIV_21_DIRECT_COST'+\\\n",
    "            ',DIV_22_DIRECT_COST'+\\\n",
    "            ',DIV_23_DIRECT_COST'+\\\n",
    "            ',DIV_26_DIRECT_COST'+\\\n",
    "            ',DIV_27_DIRECT_COST'+\\\n",
    "            ',DIV_28_DIRECT_COST'+\\\n",
    "            ',DIV_31_DIRECT_COST'+\\\n",
    "            ',DIV_32_DIRECT_COST'+\\\n",
    "            ',DIV_33_DIRECT_COST'+\\\n",
    "            ',DIV_34_DIRECT_COST'+\\\n",
    "            ',DIV_55_DIRECT_COST'+\\\n",
    "            ',GCS_COST'+\\\n",
    "            ',GRS_COST '+\\\n",
    "            'from sandbox.global.ml_grs_fit ' \n",
    "df_data = load_data(query).set_index('JOB') \n",
    "df_data = pd.DataFrame(df_data)\n",
    "df_data = df_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DIRECT_COST</th>\n",
       "      <th>DIV_00_DIRECT_COST</th>\n",
       "      <th>DIV_01_DIRECT_COST</th>\n",
       "      <th>DIV_02_DIRECT_COST</th>\n",
       "      <th>DIV_03_DIRECT_COST</th>\n",
       "      <th>DIV_04_DIRECT_COST</th>\n",
       "      <th>DIV_05_DIRECT_COST</th>\n",
       "      <th>DIV_06_DIRECT_COST</th>\n",
       "      <th>DIV_07_DIRECT_COST</th>\n",
       "      <th>DIV_08_DIRECT_COST</th>\n",
       "      <th>...</th>\n",
       "      <th>DIV_26_DIRECT_COST</th>\n",
       "      <th>DIV_27_DIRECT_COST</th>\n",
       "      <th>DIV_28_DIRECT_COST</th>\n",
       "      <th>DIV_31_DIRECT_COST</th>\n",
       "      <th>DIV_32_DIRECT_COST</th>\n",
       "      <th>DIV_33_DIRECT_COST</th>\n",
       "      <th>DIV_34_DIRECT_COST</th>\n",
       "      <th>DIV_55_DIRECT_COST</th>\n",
       "      <th>GCS_COST</th>\n",
       "      <th>GRS_COST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2,753,305.18</td>\n",
       "      <td>15,416.14</td>\n",
       "      <td>1,095.30</td>\n",
       "      <td>120,305.74</td>\n",
       "      <td>305,087.19</td>\n",
       "      <td>25,975.15</td>\n",
       "      <td>192,784.27</td>\n",
       "      <td>83,875.74</td>\n",
       "      <td>97,562.86</td>\n",
       "      <td>262,156.35</td>\n",
       "      <td>...</td>\n",
       "      <td>279,623.43</td>\n",
       "      <td>22,192.54</td>\n",
       "      <td>7,159.77</td>\n",
       "      <td>84,671.51</td>\n",
       "      <td>18,546.22</td>\n",
       "      <td>19,750.99</td>\n",
       "      <td>505.83</td>\n",
       "      <td>1,710.05</td>\n",
       "      <td>159,975.26</td>\n",
       "      <td>130,762.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18,205,353.59</td>\n",
       "      <td>247,803.94</td>\n",
       "      <td>21,856.71</td>\n",
       "      <td>835,518.53</td>\n",
       "      <td>2,456,075.21</td>\n",
       "      <td>255,679.11</td>\n",
       "      <td>1,926,522.10</td>\n",
       "      <td>479,208.15</td>\n",
       "      <td>712,596.43</td>\n",
       "      <td>2,347,850.24</td>\n",
       "      <td>...</td>\n",
       "      <td>2,283,423.57</td>\n",
       "      <td>355,302.65</td>\n",
       "      <td>98,050.42</td>\n",
       "      <td>852,341.42</td>\n",
       "      <td>200,217.24</td>\n",
       "      <td>315,920.99</td>\n",
       "      <td>14,397.44</td>\n",
       "      <td>98,425.42</td>\n",
       "      <td>991,159.86</td>\n",
       "      <td>893,014.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3,404,153.00</td>\n",
       "      <td>-327,264.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-41,282.56</td>\n",
       "      <td>-4,315,458.20</td>\n",
       "      <td>-164,664.12</td>\n",
       "      <td>-1,398,362.17</td>\n",
       "      <td>-174,550.72</td>\n",
       "      <td>-16,197.24</td>\n",
       "      <td>-407,656.41</td>\n",
       "      <td>...</td>\n",
       "      <td>-104.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-2,322.10</td>\n",
       "      <td>-11.50</td>\n",
       "      <td>-53,330.53</td>\n",
       "      <td>-4.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-3,335,087.00</td>\n",
       "      <td>-629,785.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4,410.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>554.25</td>\n",
       "      <td>305.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31,937.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>889.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>353.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>37.68</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4,763.00</td>\n",
       "      <td>2,099.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>279,720.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10,486.36</td>\n",
       "      <td>1,041.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>180.50</td>\n",
       "      <td>10,992.53</td>\n",
       "      <td>44.95</td>\n",
       "      <td>9,230.26</td>\n",
       "      <td>...</td>\n",
       "      <td>3,893.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35,369.50</td>\n",
       "      <td>16,783.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>399,570,438.00</td>\n",
       "      <td>8,618,727.16</td>\n",
       "      <td>762,087.69</td>\n",
       "      <td>26,715,320.64</td>\n",
       "      <td>49,560,386.64</td>\n",
       "      <td>9,635,075.36</td>\n",
       "      <td>51,850,542.49</td>\n",
       "      <td>9,711,287.61</td>\n",
       "      <td>19,337,427.69</td>\n",
       "      <td>56,887,683.67</td>\n",
       "      <td>...</td>\n",
       "      <td>57,604,860.12</td>\n",
       "      <td>14,904,687.98</td>\n",
       "      <td>2,706,150.04</td>\n",
       "      <td>19,786,153.90</td>\n",
       "      <td>6,898,015.60</td>\n",
       "      <td>10,785,799.69</td>\n",
       "      <td>607,500.00</td>\n",
       "      <td>5,681,453.04</td>\n",
       "      <td>23,749,853.00</td>\n",
       "      <td>18,182,714.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DIRECT_COST  DIV_00_DIRECT_COST  DIV_01_DIRECT_COST  \\\n",
       "count       3,332.00            3,332.00            3,332.00   \n",
       "mean    2,753,305.18           15,416.14            1,095.30   \n",
       "std    18,205,353.59          247,803.94           21,856.71   \n",
       "min    -3,404,153.00         -327,264.32                0.00   \n",
       "25%         4,410.75                0.00                0.00   \n",
       "50%        31,937.00                0.00                0.00   \n",
       "75%       279,720.25                0.00                0.00   \n",
       "max   399,570,438.00        8,618,727.16          762,087.69   \n",
       "\n",
       "       DIV_02_DIRECT_COST  DIV_03_DIRECT_COST  DIV_04_DIRECT_COST  \\\n",
       "count            3,332.00            3,332.00            3,332.00   \n",
       "mean           120,305.74          305,087.19           25,975.15   \n",
       "std            835,518.53        2,456,075.21          255,679.11   \n",
       "min            -41,282.56       -4,315,458.20         -164,664.12   \n",
       "25%                  0.00                0.00                0.00   \n",
       "50%                889.22                0.00                0.00   \n",
       "75%             10,486.36            1,041.34                0.00   \n",
       "max         26,715,320.64       49,560,386.64        9,635,075.36   \n",
       "\n",
       "       DIV_05_DIRECT_COST  DIV_06_DIRECT_COST  DIV_07_DIRECT_COST  \\\n",
       "count            3,332.00            3,332.00            3,332.00   \n",
       "mean           192,784.27           83,875.74           97,562.86   \n",
       "std          1,926,522.10          479,208.15          712,596.43   \n",
       "min         -1,398,362.17         -174,550.72          -16,197.24   \n",
       "25%                  0.00                0.00                0.00   \n",
       "50%                  0.00              353.55                0.00   \n",
       "75%                180.50           10,992.53               44.95   \n",
       "max         51,850,542.49        9,711,287.61       19,337,427.69   \n",
       "\n",
       "       DIV_08_DIRECT_COST  ...  DIV_26_DIRECT_COST  DIV_27_DIRECT_COST  \\\n",
       "count            3,332.00  ...            3,332.00            3,332.00   \n",
       "mean           262,156.35  ...          279,623.43           22,192.54   \n",
       "std          2,347,850.24  ...        2,283,423.57          355,302.65   \n",
       "min           -407,656.41  ...             -104.77                0.00   \n",
       "25%                  0.00  ...                0.00                0.00   \n",
       "50%                 37.68  ...                0.00                0.00   \n",
       "75%              9,230.26  ...            3,893.87                0.00   \n",
       "max         56,887,683.67  ...       57,604,860.12       14,904,687.98   \n",
       "\n",
       "       DIV_28_DIRECT_COST  DIV_31_DIRECT_COST  DIV_32_DIRECT_COST  \\\n",
       "count            3,332.00            3,332.00            3,332.00   \n",
       "mean             7,159.77           84,671.51           18,546.22   \n",
       "std             98,050.42          852,341.42          200,217.24   \n",
       "min                  0.00           -2,322.10              -11.50   \n",
       "25%                  0.00                0.00                0.00   \n",
       "50%                  0.00                0.00                0.00   \n",
       "75%                  0.00                0.00                0.00   \n",
       "max          2,706,150.04       19,786,153.90        6,898,015.60   \n",
       "\n",
       "       DIV_33_DIRECT_COST  DIV_34_DIRECT_COST  DIV_55_DIRECT_COST  \\\n",
       "count            3,332.00            3,332.00            3,332.00   \n",
       "mean            19,750.99              505.83            1,710.05   \n",
       "std            315,920.99           14,397.44           98,425.42   \n",
       "min            -53,330.53               -4.20                0.00   \n",
       "25%                  0.00                0.00                0.00   \n",
       "50%                  0.00                0.00                0.00   \n",
       "75%                  0.00                0.00                0.00   \n",
       "max         10,785,799.69          607,500.00        5,681,453.04   \n",
       "\n",
       "           GCS_COST      GRS_COST  \n",
       "count      3,332.00      3,332.00  \n",
       "mean     159,975.26    130,762.61  \n",
       "std      991,159.86    893,014.97  \n",
       "min   -3,335,087.00   -629,785.00  \n",
       "25%          554.25        305.75  \n",
       "50%        4,763.00      2,099.00  \n",
       "75%       35,369.50     16,783.00  \n",
       "max   23,749,853.00 18,182,714.00  \n",
       "\n",
       "[8 rows x 34 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_working = df_data.loc[\n",
    "                    (0 != df_data.GRS_COST) &\n",
    "                    (0 != df_data.GCS_COST)\n",
    "].copy()\n",
    "df_working.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3332,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X  = df_working.iloc[:,:-2] #.values\n",
    "y_gcs = df_working.iloc[:,-2:-1].values.ravel()\n",
    "y_grs = df_working.iloc[:,-1:].values.ravel()\n",
    "y_grs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_grs_train, y_grs_test = train_test_split(X, y_grs, test_size=0.33, random_state=42)\n",
    "X_train, X_test, y_gcs_train, y_gcs_test = train_test_split(X, y_gcs, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "\n",
    "# pipeline setup\n",
    "pipeline = Pipeline([\n",
    "                     ('scaler', None)\n",
    "                     ,('kbest', SelectKBest(f_regression))\n",
    "                     ,('stack_reg_one', StackingEstimator(estimator=AdaBoostRegressor()))\n",
    "                    #  ,('stack_reg_two', StackingEstimator(estimator=XGBRegressor(verbosity=0))) #this makes it worse\n",
    "                     ,('meta_reg', ElasticNetCV())\n",
    "                     ])\n",
    "\n",
    "parameters = {\n",
    "                'kbest__k': [6]\n",
    "                ,'stack_reg_one__estimator__learning_rate': [0.04, 0.1]\n",
    "                ,'stack_reg_one__estimator__loss': ['linear', 'exponential']\n",
    "                ,'stack_reg_one__estimator__n_estimators': [100, 150] \n",
    "                ,'meta_reg__l1_ratio':  [0.1]\n",
    "                ,'meta_reg__tol':  [0.001]\n",
    "                # ,'stack_reg_two__estimator__learning_rate': [0.1] \n",
    "                # ,'stack_reg_two__estimator__learning_rate': np.linspace(0.4, 0.6, 3) \n",
    "                # ,'stack_reg_two__estimator__max_depth': [5] \n",
    "                # ,'stack_reg_two__estimator__min_child_weight': [10] \n",
    "                # ,'stack_reg_two__estimator__n_estimators': [100] \n",
    "                # ,'stack_reg_two__estimator__objective': ['reg:squarederror'] \n",
    "                # ,'stack_reg_two__estimator__subsample': [0.9500000000000001] \n",
    "                # 'scaler':  [RobustScaler(), Normalizer(), QuantileTransformer(), MinMaxScaler()] #these make it worse\n",
    "                # ,'stack_reg__estimator__learning_rate': [0.01]\n",
    "                # ,'stack_reg__estimator__learning_rate': [0.0001, 0.001, 0.01, 0.1, 1.0] #0.01 and 0.1 are best\n",
    "                # ,'stack_reg__estimator__learning_rate': np.linspace(0.01, 0.1, 4) #0.04 and 0.1 are best\n",
    "                # ,'stack_reg__estimator__loss': ['exponential']\n",
    "                # ,'stack_reg__estimator__loss': ['linear', 'square', 'exponential'] #linear and exponential are best\n",
    "                # ,'stack_reg__estimator__n_estimators': [100]\n",
    "                # ,'stack_reg__estimator__n_estimators': [50, 100, 150] #100 and 150 are best\n",
    "                # ,'meta_reg__l1_ratio':  [0, 0.1, 0.5, 1] #this makes it worse\n",
    "                # ,'meta_reg__tol':  [0.0001, 0.001, 0.01, 0.1] #this makes it worse\n",
    "                }\n",
    "#grs model\n",
    "grs_grid = GridSearchCV(\n",
    "    pipeline\n",
    "    ,parameters\n",
    "    ,cv=cv\n",
    "    ,scoring={'R2': make_scorer(r2_score)\n",
    "            ,'negMedAE': make_scorer(utils.neg_median_absolute_error)\n",
    "    }\n",
    "    ,refit=utils.refit_strategy\n",
    "    ,return_train_score=False\n",
    "    ,n_jobs=-2\n",
    ")   \n",
    "\n",
    "#gcs model\n",
    "gcs_grid = GridSearchCV(\n",
    "    pipeline\n",
    "    ,parameters\n",
    "    ,cv=cv\n",
    "    ,scoring={'R2': make_scorer(r2_score)\n",
    "            ,'negMedAE': make_scorer(utils.neg_median_absolute_error)\n",
    "        }\n",
    "    ,refit=utils.refit_strategy\n",
    "    ,return_train_score=False\n",
    "    ,n_jobs=-2\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(100, 250, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All grid-search results:\n",
      "R2: 0.595 (±0.685), negMedAE: -12753.107 (±3439.495), for {'kbest__k': 6, 'meta_reg__l1_ratio': 0.1, 'meta_reg__tol': 0.001, 'stack_reg_one__estimator__learning_rate': 0.04, 'stack_reg_one__estimator__loss': 'linear', 'stack_reg_one__estimator__n_estimators': 100}\n",
      "R2: 0.596 (±0.686), negMedAE: -11312.950 (±2634.968), for {'kbest__k': 6, 'meta_reg__l1_ratio': 0.1, 'meta_reg__tol': 0.001, 'stack_reg_one__estimator__learning_rate': 0.04, 'stack_reg_one__estimator__loss': 'linear', 'stack_reg_one__estimator__n_estimators': 150}\n",
      "R2: 0.596 (±0.687), negMedAE: -13489.665 (±3176.153), for {'kbest__k': 6, 'meta_reg__l1_ratio': 0.1, 'meta_reg__tol': 0.001, 'stack_reg_one__estimator__learning_rate': 0.04, 'stack_reg_one__estimator__loss': 'exponential', 'stack_reg_one__estimator__n_estimators': 100}\n",
      "R2: 0.594 (±0.688), negMedAE: -12023.655 (±2918.774), for {'kbest__k': 6, 'meta_reg__l1_ratio': 0.1, 'meta_reg__tol': 0.001, 'stack_reg_one__estimator__learning_rate': 0.04, 'stack_reg_one__estimator__loss': 'exponential', 'stack_reg_one__estimator__n_estimators': 150}\n",
      "R2: 0.598 (±0.689), negMedAE: -8833.568 (±2921.375), for {'kbest__k': 6, 'meta_reg__l1_ratio': 0.1, 'meta_reg__tol': 0.001, 'stack_reg_one__estimator__learning_rate': 0.1, 'stack_reg_one__estimator__loss': 'linear', 'stack_reg_one__estimator__n_estimators': 100}\n",
      "R2: 0.598 (±0.693), negMedAE: -6373.092 (±3595.001), for {'kbest__k': 6, 'meta_reg__l1_ratio': 0.1, 'meta_reg__tol': 0.001, 'stack_reg_one__estimator__learning_rate': 0.1, 'stack_reg_one__estimator__loss': 'linear', 'stack_reg_one__estimator__n_estimators': 150}\n",
      "R2: 0.598 (±0.691), negMedAE: -8854.740 (±2606.970), for {'kbest__k': 6, 'meta_reg__l1_ratio': 0.1, 'meta_reg__tol': 0.001, 'stack_reg_one__estimator__learning_rate': 0.1, 'stack_reg_one__estimator__loss': 'exponential', 'stack_reg_one__estimator__n_estimators': 100}\n",
      "R2: 0.591 (±0.697), negMedAE: -5698.175 (±3954.740), for {'kbest__k': 6, 'meta_reg__l1_ratio': 0.1, 'meta_reg__tol': 0.001, 'stack_reg_one__estimator__learning_rate': 0.1, 'stack_reg_one__estimator__loss': 'exponential', 'stack_reg_one__estimator__n_estimators': 150}\n",
      "\n",
      "Models in the top 10% by R2:\n",
      "R2: 0.598 (±0.689), negMedAE: -8833.568 (±2921.375), for {'kbest__k': 6, 'meta_reg__l1_ratio': 0.1, 'meta_reg__tol': 0.001, 'stack_reg_one__estimator__learning_rate': 0.1, 'stack_reg_one__estimator__loss': 'linear', 'stack_reg_one__estimator__n_estimators': 100}\n",
      "R2: 0.598 (±0.693), negMedAE: -6373.092 (±3595.001), for {'kbest__k': 6, 'meta_reg__l1_ratio': 0.1, 'meta_reg__tol': 0.001, 'stack_reg_one__estimator__learning_rate': 0.1, 'stack_reg_one__estimator__loss': 'linear', 'stack_reg_one__estimator__n_estimators': 150}\n",
      "R2: 0.598 (±0.691), negMedAE: -8854.740 (±2606.970), for {'kbest__k': 6, 'meta_reg__l1_ratio': 0.1, 'meta_reg__tol': 0.001, 'stack_reg_one__estimator__learning_rate': 0.1, 'stack_reg_one__estimator__loss': 'exponential', 'stack_reg_one__estimator__n_estimators': 100}\n",
      "\n",
      "\n",
      "The selected final model is the best negMedAE out of the previously\n",
      "selected subset of best models based on R2 - 0.1.\n",
      "Its details are:\n",
      "\n",
      "mean_score_time                                                    0.04\n",
      "mean_test_R2                                                       0.60\n",
      "std_test_R2                                                        0.69\n",
      "mean_test_negMedAE                                            -6,373.09\n",
      "std_test_negMedAE                                              3,595.00\n",
      "rank_test_R2                                                          2\n",
      "rank_test_negMedAE                                                    2\n",
      "params                {'kbest__k': 6, 'meta_reg__l1_ratio': 0.1, 'me...\n",
      "Name: 5, dtype: object\n"
     ]
    }
   ],
   "source": [
    "grs_grid = grs_grid.fit(X_train, y_grs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All grid-search results:\n",
      "R2: 0.572 (±0.291), negMedAE: -13651.603 (±6177.409), for {'kbest__k': 6, 'meta_reg__l1_ratio': 0.1, 'meta_reg__tol': 0.001, 'stack_reg_one__estimator__learning_rate': 0.04, 'stack_reg_one__estimator__loss': 'linear', 'stack_reg_one__estimator__n_estimators': 100}\n",
      "R2: 0.564 (±0.315), negMedAE: -20557.140 (±10650.220), for {'kbest__k': 6, 'meta_reg__l1_ratio': 0.1, 'meta_reg__tol': 0.001, 'stack_reg_one__estimator__learning_rate': 0.04, 'stack_reg_one__estimator__loss': 'linear', 'stack_reg_one__estimator__n_estimators': 150}\n",
      "R2: 0.570 (±0.307), negMedAE: -13514.559 (±4051.953), for {'kbest__k': 6, 'meta_reg__l1_ratio': 0.1, 'meta_reg__tol': 0.001, 'stack_reg_one__estimator__learning_rate': 0.04, 'stack_reg_one__estimator__loss': 'exponential', 'stack_reg_one__estimator__n_estimators': 100}\n",
      "R2: 0.563 (±0.286), negMedAE: -18896.210 (±11545.133), for {'kbest__k': 6, 'meta_reg__l1_ratio': 0.1, 'meta_reg__tol': 0.001, 'stack_reg_one__estimator__learning_rate': 0.04, 'stack_reg_one__estimator__loss': 'exponential', 'stack_reg_one__estimator__n_estimators': 150}\n",
      "R2: 0.565 (±0.284), negMedAE: -37423.736 (±12990.116), for {'kbest__k': 6, 'meta_reg__l1_ratio': 0.1, 'meta_reg__tol': 0.001, 'stack_reg_one__estimator__learning_rate': 0.1, 'stack_reg_one__estimator__loss': 'linear', 'stack_reg_one__estimator__n_estimators': 100}\n",
      "R2: 0.555 (±0.291), negMedAE: -41171.588 (±16641.378), for {'kbest__k': 6, 'meta_reg__l1_ratio': 0.1, 'meta_reg__tol': 0.001, 'stack_reg_one__estimator__learning_rate': 0.1, 'stack_reg_one__estimator__loss': 'linear', 'stack_reg_one__estimator__n_estimators': 150}\n",
      "R2: 0.568 (±0.288), negMedAE: -42717.787 (±11328.097), for {'kbest__k': 6, 'meta_reg__l1_ratio': 0.1, 'meta_reg__tol': 0.001, 'stack_reg_one__estimator__learning_rate': 0.1, 'stack_reg_one__estimator__loss': 'exponential', 'stack_reg_one__estimator__n_estimators': 100}\n",
      "R2: 0.545 (±0.299), negMedAE: -56844.497 (±15659.978), for {'kbest__k': 6, 'meta_reg__l1_ratio': 0.1, 'meta_reg__tol': 0.001, 'stack_reg_one__estimator__learning_rate': 0.1, 'stack_reg_one__estimator__loss': 'exponential', 'stack_reg_one__estimator__n_estimators': 150}\n",
      "\n",
      "Models in the top 10% by R2:\n",
      "R2: 0.572 (±0.291), negMedAE: -13651.603 (±6177.409), for {'kbest__k': 6, 'meta_reg__l1_ratio': 0.1, 'meta_reg__tol': 0.001, 'stack_reg_one__estimator__learning_rate': 0.04, 'stack_reg_one__estimator__loss': 'linear', 'stack_reg_one__estimator__n_estimators': 100}\n",
      "R2: 0.570 (±0.307), negMedAE: -13514.559 (±4051.953), for {'kbest__k': 6, 'meta_reg__l1_ratio': 0.1, 'meta_reg__tol': 0.001, 'stack_reg_one__estimator__learning_rate': 0.04, 'stack_reg_one__estimator__loss': 'exponential', 'stack_reg_one__estimator__n_estimators': 100}\n",
      "R2: 0.568 (±0.288), negMedAE: -42717.787 (±11328.097), for {'kbest__k': 6, 'meta_reg__l1_ratio': 0.1, 'meta_reg__tol': 0.001, 'stack_reg_one__estimator__learning_rate': 0.1, 'stack_reg_one__estimator__loss': 'exponential', 'stack_reg_one__estimator__n_estimators': 100}\n",
      "\n",
      "\n",
      "The selected final model is the best negMedAE out of the previously\n",
      "selected subset of best models based on R2 - 0.1.\n",
      "Its details are:\n",
      "\n",
      "mean_score_time                                                    0.03\n",
      "mean_test_R2                                                       0.57\n",
      "std_test_R2                                                        0.31\n",
      "mean_test_negMedAE                                           -13,514.56\n",
      "std_test_negMedAE                                              4,051.95\n",
      "rank_test_R2                                                          2\n",
      "rank_test_negMedAE                                                    1\n",
      "params                {'kbest__k': 6, 'meta_reg__l1_ratio': 0.1, 'me...\n",
      "Name: 2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "gcs_grid = gcs_grid.fit(X_train, y_gcs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for test grs data: 0.7485719311610892\n",
      "negMedAE for test grs data: -3688.770049160108\n"
     ]
    }
   ],
   "source": [
    "y_grs_test_pred = grs_grid.best_estimator_.predict(X_test)\n",
    "print(f'R2 for test grs data: {r2_score(y_grs_test, y_grs_test_pred)}')\n",
    "print(f'negMedAE for test grs data: {utils.neg_median_absolute_error(y_grs_test, y_grs_test_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for test gcs data: 0.6695924716738761\n",
      "negMedAE for test gcs data: -15460.492543087541\n"
     ]
    }
   ],
   "source": [
    "y_gcs_test_pred = gcs_grid.best_estimator_.predict(X_test)\n",
    "print(f'R2 for test gcs data: {r2_score(y_gcs_test, y_gcs_test_pred)}')\n",
    "print(f'negMedAE for test gcs data: {utils.neg_median_absolute_error(y_gcs_test, y_gcs_test_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_grid_test = gcs_grid.best_estimator_.fit(X_test, y_gcs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"the best grs estimator is \\n {} \".format(grs_grid.best_estimator_))\n",
    "print(\"the best grs parameters are \\n {}\".format(grs_grid.best_params_))\n",
    "print(\"the best gcs estimator is \\n {} \".format(gcs_grid.best_estimator_))\n",
    "print(\"the best gcs parameters are \\n {}\".format(gcs_grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grs_best_pipe = grs_grid.best_estimator_\n",
    "grs_mask = list(grs_best_pipe.fit(X,y_grs)[:-1].get_feature_names_out())\n",
    "grs_model = grs_best_pipe.fit(df_working[grs_mask],y_grs)\n",
    "grs_predictions = grs_model.predict(df_working[grs_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_best_pipe = gcs_grid.best_estimator_\n",
    "gcs_mask = list(gcs_best_pipe.fit(X,y_gcs)[:-1].get_feature_names_out())\n",
    "gcs_model = gcs_best_pipe.fit(df_working[gcs_mask],y_gcs)\n",
    "gcs_predictions = gcs_model.predict(df_working[gcs_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(grs_model[:-1].get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grs_parameters = list(df_working[grs_mask].columns)\n",
    "gcs_parameters = list(df_working[gcs_mask].columns)\n",
    "combined_mask = list(set(grs_parameters + gcs_parameters))\n",
    "df = df_working[combined_mask].copy()\n",
    "df['GRS_PREDICTIONS'] = grs_predictions\n",
    "df['GCS_PREDICTIONS'] = gcs_predictions\n",
    "knnr_model_bag = {\n",
    "    'df': df\n",
    "    ,'grs_model': grs_model\n",
    "    ,'grs_parameters': grs_parameters\n",
    "    ,'gcs_model': gcs_model\n",
    "    ,'gcs_parameters': gcs_parameters\n",
    "}\n",
    "with open('./app/knnr_model_bag.pkl','wb') as p:\n",
    "    pickle.dump(knnr_model_bag, p, protocol=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./app/model_bag.pkl','rb') as p:\n",
    "    bag = pickle.load(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grs_params = bag['grs_parameters']\n",
    "gcs_params = bag['gcs_parameters']\n",
    "all_params = list(set(grs_params + gcs_params))\n",
    "test_vec = bag['df'][all_params].sample(1).copy()\n",
    "# bag['grs_model'].predict(test_vec)\n",
    "# model = bag['grs_model']\n",
    "# list(model[:-1].get_feature_names_out())\n",
    "print(*list(test_vec[grs_params].columns), sep='\\n,')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = test_vec.reset_index(drop=True).T\n",
    "vec.index.names = ['PARAMETERS']\n",
    "vec = vec.reset_index()\n",
    "vec.set_index('PARAMETERS').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag['grs_model'].predict(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the features scores rounded in 2 decimals\n",
    "pip_steps = grs_grid.best_estimator_.named_steps['kbest']\n",
    "pip_steps.get_support()\n",
    "\n",
    "features_scores = ['%.2f' % elem for elem in pip_steps.scores_ ]\n",
    "print(\"the features scores are \\n {}\".format(features_scores))\n",
    "\n",
    "feature_scores_pvalues = ['%.3f' % elem for elem in pip_steps.pvalues_]\n",
    "print(\"the feature_pvalues is \\n {} \".format(feature_scores_pvalues))\n",
    "\n",
    "scored_features = pd.DataFrame(df_working[grs_mask].columns, columns=['feature_names'])\n",
    "scored_features['feature_scores'] = features_scores\n",
    "scored_features['feature_scores_pvalues'] = feature_scores_pvalues\n",
    "scored_features = scored_features.loc[(scored_features['feature_scores'] != 'nan') & (scored_features['feature_scores'] != 'inf')].sort_values(by='feature_scores', ascending=False).iloc[:num_features]\n",
    "scored_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = scored_features.feature_names.to_list()\n",
    "df_working[selected_features].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(neigh, open('grs_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grs_model = pickle.load(open('grs_model.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(data_preds, open('grs_model.pkl','ab+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grs_data = []\n",
    "with open('./app/grs_model.pkl', 'rb') as fr:\n",
    "    try:\n",
    "        while True:\n",
    "            grs_data.append(pickle.load(fr))\n",
    "    except EOFError:\n",
    "        pass\n",
    "gcs_data = []\n",
    "with open('./app/gcs_model.pkl', 'rb') as fr:\n",
    "    try:\n",
    "        while True:\n",
    "            gcs_data.append(pickle.load(fr))\n",
    "    except EOFError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grs_model, grs_preds = grs_data\n",
    "gcs_model, gcs_preds = gcs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphWidth = 1500\n",
    "graphHeight = graphWidth * 800 / 1000\n",
    "x_plot = data_preds.DIRECT_COST\n",
    "y1_plot = data_preds.GRS_ACTUAL\n",
    "y2_plot = data_preds.GRS_PREDICTIONS\n",
    "f = plt.figure(figsize=(graphWidth/100.0, graphHeight/100.0), dpi=100)\n",
    "axes = f.add_subplot(111)\n",
    "axes.plot(x_plot, y1_plot, c='g', alpha=0.15)\n",
    "axes.plot(x_plot, y2_plot, alpha=0.15)\n",
    "axes.scatter(direct_cost, grs_cost, c='r', marker='D')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grs_fit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join, dirname\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pickle\n",
    "from snowflake import connector\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter, StrMethodFormatter\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.preprocessing import Normalizer, QuantileTransformer, RobustScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, mean_squared_log_error, mean_absolute_percentage_error, median_absolute_error, max_error, make_scorer\n",
    "\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "# get environment variables\n",
    "dotenv_path = join(dirname('streamlit_grs_fit\\\\app\\\\'), '.env')\n",
    "load_dotenv(dotenv_path)\n",
    "SF_ACCOUNT = os.getenv('SF_ACCOUNT')\n",
    "SF_USER = os.getenv('SF_USER')\n",
    "SF_PASSWORD = os.getenv('SF_PASSWORD')\n",
    "SF_ROLE = os.getenv('SF_ROLE')\n",
    "SF_WAREHOUSE = os.getenv('SF_WAREHOUSE')\n",
    "SF_DATABASE = os.getenv('SF_DATABASE')\n",
    "SF_SCHEMA = os.getenv('SF_SCHEMA')\n",
    "\n",
    "def load_data(query):\n",
    "    conn = connector.connect(\n",
    "        user = SF_USER\n",
    "        ,password = SF_PASSWORD\n",
    "        ,account = SF_ACCOUNT\n",
    "        ,warehouse = SF_WAREHOUSE\n",
    "        ,database = SF_DATABASE\n",
    "        ,schema = SF_SCHEMA\n",
    "        ,role = SF_ROLE\n",
    "    )\n",
    "    cur = conn.cursor()\n",
    "    df_data = cur.execute(query).fetch_pandas_all()\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'select '+\\\n",
    "            'JOB'+\\\n",
    "            ',DIRECT_COST'+\\\n",
    "            ',DIV_00_DIRECT_COST'+\\\n",
    "            ',DIV_01_DIRECT_COST'+\\\n",
    "            ',DIV_02_DIRECT_COST'+\\\n",
    "            ',DIV_03_DIRECT_COST'+\\\n",
    "            ',DIV_04_DIRECT_COST'+\\\n",
    "            ',DIV_05_DIRECT_COST'+\\\n",
    "            ',DIV_06_DIRECT_COST'+\\\n",
    "            ',DIV_07_DIRECT_COST'+\\\n",
    "            ',DIV_08_DIRECT_COST'+\\\n",
    "            ',DIV_09_DIRECT_COST'+\\\n",
    "            ',DIV_10_DIRECT_COST'+\\\n",
    "            ',DIV_11_DIRECT_COST'+\\\n",
    "            ',DIV_12_DIRECT_COST'+\\\n",
    "            ',DIV_13_DIRECT_COST'+\\\n",
    "            ',DIV_14_DIRECT_COST'+\\\n",
    "            ',DIV_15_DIRECT_COST'+\\\n",
    "            ',DIV_16_DIRECT_COST'+\\\n",
    "            ',DIV_17_DIRECT_COST'+\\\n",
    "            ',DIV_18_DIRECT_COST'+\\\n",
    "            ',DIV_19_DIRECT_COST'+\\\n",
    "            ',DIV_21_DIRECT_COST'+\\\n",
    "            ',DIV_22_DIRECT_COST'+\\\n",
    "            ',DIV_23_DIRECT_COST'+\\\n",
    "            ',DIV_26_DIRECT_COST'+\\\n",
    "            ',DIV_27_DIRECT_COST'+\\\n",
    "            ',DIV_28_DIRECT_COST'+\\\n",
    "            ',DIV_31_DIRECT_COST'+\\\n",
    "            ',DIV_32_DIRECT_COST'+\\\n",
    "            ',DIV_33_DIRECT_COST'+\\\n",
    "            ',DIV_34_DIRECT_COST'+\\\n",
    "            ',DIV_55_DIRECT_COST'+\\\n",
    "            ',GCS_COST'+\\\n",
    "            ',GRS_COST '+\\\n",
    "            'from sandbox.global.ml_grs_fit ' \n",
    "df_data = load_data(query).set_index('JOB') \n",
    "df_data = pd.DataFrame(df_data)\n",
    "df_data = df_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_working = df_data.loc[\n",
    "                    (0 != df_data.GRS_COST) &\n",
    "                    (0 != df_data.GCS_COST)\n",
    "].copy()\n",
    "df_working.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X  = df_working.iloc[:,:-2] #.values\n",
    "y_gcs = df_working.iloc[:,-2:-1].values.ravel()\n",
    "y_grs = df_working.iloc[:,-1:].values.ravel()\n",
    "y_grs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last itteration, I got everything I was trying to do to work. that is, I trained a model and saved it as a binary object that can be packaged with an app, and tested the implementation within the app framework. \n",
    "that part all works great! it's super fast, and I think we'll be able to get the ui pretty nice at the end.\n",
    "the thing to be aware of at this point is that it can't be expected to be reliable. yet\n",
    "here's what I think are next steps in order to make it as reliable as possible, and to be able to know exactly how reliable it is. this is what I'll do in this itteration:\n",
    "1.  identify metrics by which model success will be measured. e.g., MSE, RMSE, MAE, MAPE\n",
    "2.  implement train / test split prior to cross validation\n",
    "3.  rerun the cross validation setup for this estimator (knearestneighborsregressor) with the training data only\n",
    "4.  evaluate, in terms of our selected metrics, the model selected by cross validation against the test data (to which it would be naïve at this point. this will guard us against data leakage)\n",
    "5.  repeat steps 3 and 4 for a few other estimators. I'm thinking lasso, elasticnet, maybe ridgeregression or svr, and perhaps mlpregressor if we're feeling ambitious\n",
    "compare the scores of our models and pick the best one\n",
    "\n",
    "initially, trying these scorers: r2_score, mean_absolute_error, mean_squared_error, mean_squared_log_error, mean_absolute_percentage_error, median_absolute_error, max_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_grs_train, y_grs_test = train_test_split(X, y_grs, test_size=0.33, random_state=42)\n",
    "X_train, X_test, y_gcs_train, y_gcs_test = train_test_split(X, y_gcs, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dataframe(filtered_cv_results):\n",
    "    \"\"\"Pretty print for filtered dataframe\"\"\"\n",
    "    for mean_r2, std_r2, mean_negmedae, std_negmedae, params in zip(\n",
    "        filtered_cv_results[\"mean_test_R2\"],\n",
    "        filtered_cv_results[\"std_test_R2\"],\n",
    "        filtered_cv_results[\"mean_test_negMedAE\"],\n",
    "        filtered_cv_results[\"std_test_negMedAE\"],\n",
    "        filtered_cv_results[\"params\"],\n",
    "    ):\n",
    "        print(\n",
    "            f\"R2: {mean_r2:0.3f} (±{std_r2:0.03f}),\"\n",
    "            f\" negMedAE: {mean_negmedae:0.3f} (±{std_negmedae:0.03f}),\"\n",
    "            f\" for {params}\"\n",
    "        )\n",
    "    print()\n",
    "\n",
    "def refit_strategy(cv_results):\n",
    "    \"\"\"Define the strategy to select the best estimator.\n",
    "\n",
    "    The strategy defined here is to filter-out all results below a R2 threshold\n",
    "    of 0.5, rank the remaining by MedAE and keep all models with one standard\n",
    "    deviation of the best by MedAE. Once these models are selected, we can select the\n",
    "    fastest model to predict.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cv_results : dict of numpy (masked) ndarrays\n",
    "        CV results as returned by the `GridSearchCV`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    best_index : int\n",
    "        The index of the best estimator as it appears in `cv_results`.\n",
    "    \"\"\"\n",
    "    # print the info about the grid-search for the different scores\n",
    "    r2_threshold = 0.67\n",
    "\n",
    "    cv_results_ = pd.DataFrame(cv_results)\n",
    "    print(\"All grid-search results:\")\n",
    "    print_dataframe(cv_results_)\n",
    "\n",
    "    # Filter-out all results below the threshold\n",
    "    high_r2_cv_results = cv_results_[\n",
    "        cv_results_[\"mean_test_R2\"] > r2_threshold\n",
    "    ]\n",
    "\n",
    "    print(f\"Models with an R2 higher than {r2_threshold}:\")\n",
    "    print_dataframe(high_r2_cv_results)\n",
    "\n",
    "    high_r2_cv_results = high_r2_cv_results[\n",
    "        [\n",
    "            \"mean_score_time\",\n",
    "            \"mean_test_R2\",\n",
    "            \"std_test_R2\",\n",
    "            \"mean_test_negMedAE\",\n",
    "            \"std_test_negMedAE\",\n",
    "            \"rank_test_R2\",\n",
    "            \"rank_test_negMedAE\",\n",
    "            \"params\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # Select the most performant models in terms of negMedAE\n",
    "    # (within 1 sigma from the best)\n",
    "    best_negmedae_std = high_r2_cv_results[\"mean_test_negMedAE\"].std()\n",
    "    best_negmedae = high_r2_cv_results[\"mean_test_negMedAE\"].max()\n",
    "    best_negmedae_threshold = best_negmedae - best_negmedae_std\n",
    "\n",
    "    high_negmedae_cv_results = high_r2_cv_results[\n",
    "        high_r2_cv_results[\"mean_test_negMedAE\"] > best_negmedae_threshold\n",
    "    ]\n",
    "    print(\n",
    "        \"Out of the previously selected high R2 models, we keep all the\\n\"\n",
    "        \"the models within one standard deviation of the highest negMedAE model:\"\n",
    "    )\n",
    "    print_dataframe(high_negmedae_cv_results)\n",
    "\n",
    "    # From the best candidates, select the fastest model to predict\n",
    "    fastest_top_negmedae_high_r2_index = high_negmedae_cv_results[\n",
    "        \"mean_score_time\"\n",
    "    ].idxmin()\n",
    "\n",
    "    print(\n",
    "        \"\\nThe selected final model is the fastest to predict out of the previously\\n\"\n",
    "        \"selected subset of best models based on R2 and negMedAE.\\n\"\n",
    "        \"Its scoring time is:\\n\\n\"\n",
    "        f\"{high_negmedae_cv_results.loc[fastest_top_negmedae_high_r2_index]}\"\n",
    "    )\n",
    "\n",
    "    return fastest_top_negmedae_high_r2_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a custom scorer\n",
    "def neg_median_absolute_error(y_true, y_pred):\n",
    "    medae = median_absolute_error(y_true, y_pred)\n",
    "    return -medae\n",
    "\n",
    "# pipeline setup\n",
    "pipeline = Pipeline([\n",
    "                     ('scaler', RobustScaler())            #start with this scaler. scalers account for differences in scale between features\n",
    "                    ,('kbest', SelectKBest(f_classif))     #select k best indy vars where k = winning parameter below\n",
    "                     ,('regressor', Lasso())                #the estimator, aka the ai\n",
    "                     ])\n",
    "\n",
    "parameters = {\n",
    "                'scaler':  [RobustScaler(), Normalizer(), QuantileTransformer()]   #try all these scalers\n",
    "                ,'kbest__k':  list(range(1, X.shape[1]+1))                         #with all these numbers of best indy vars (between 1 and the number of vars)\n",
    "                ,'regressor__alpha':[0.005, 0.02, 0.03, 0.05, 0.06]                #try various alpha settings\n",
    "                }\n",
    "#grs model\n",
    "grs_grid = GridSearchCV(\n",
    "    pipeline\n",
    "    ,parameters\n",
    "    ,cv=10\n",
    "    ,scoring={'R2': make_scorer(r2_score)\n",
    "            ,'negMedAE': make_scorer(neg_median_absolute_error)\n",
    "    }\n",
    "    # ,refit='R2'\n",
    "    ,refit=refit_strategy\n",
    "    ,return_train_score=False\n",
    "    ,n_jobs=-1\n",
    ")   \n",
    "\n",
    "#gcs model\n",
    "gcs_grid = GridSearchCV(\n",
    "    pipeline\n",
    "    ,parameters\n",
    "    ,cv=10\n",
    "    ,scoring={'R2': make_scorer(r2_score)\n",
    "            ,'negMedAE': make_scorer(neg_median_absolute_error)\n",
    "    }\n",
    "    ,refit=refit_strategy\n",
    "    ,return_train_score=False\n",
    "    ,n_jobs=-1\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grs_grid = grs_grid.fit(X_train, y_grs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_grid = gcs_grid.fit(X_train, y_gcs_train) #fails to converge, therefore knnr is superior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_grs_test_pred = grs_grid.best_estimator_.predict(X_test)\n",
    "print(f'R2 for test grs data: {r2_score(y_grs_test, y_grs_test_pred)}')\n",
    "print(f'negMedAE for test grs data: {neg_median_absolute_error(y_grs_test, y_grs_test_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gcs_test_pred = gcs_grid.best_estimator_.predict(X_test)\n",
    "print(f'R2 for test gcs data: {r2_score(y_gcs_test, y_gcs_test_pred)}')\n",
    "print(f'negMedAE for test gcs data: {neg_median_absolute_error(y_gcs_test, y_gcs_test_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_grid_test = gcs_grid.best_estimator_.fit(X_test, y_gcs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"the best grs estimator is \\n {} \".format(grs_grid.best_estimator_))\n",
    "print(\"the best grs parameters are \\n {}\".format(grs_grid.best_params_))\n",
    "print(\"the best gcs estimator is \\n {} \".format(gcs_grid.best_estimator_))\n",
    "print(\"the best gcs parameters are \\n {}\".format(gcs_grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grs_best_pipe = grs_grid.best_estimator_\n",
    "grs_mask = list(grs_best_pipe.fit(X,y_grs)[:-1].get_feature_names_out())\n",
    "grs_model = grs_best_pipe.fit(df_working[grs_mask],y_grs)\n",
    "grs_predictions = grs_model.predict(df_working[grs_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_best_pipe = gcs_grid.best_estimator_\n",
    "gcs_mask = list(gcs_best_pipe.fit(X,y_gcs)[:-1].get_feature_names_out())\n",
    "gcs_model = gcs_best_pipe.fit(df_working[gcs_mask],y_gcs)\n",
    "gcs_predictions = gcs_model.predict(df_working[gcs_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(grs_model[:-1].get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grs_parameters = list(df_working[grs_mask].columns)\n",
    "gcs_parameters = list(df_working[gcs_mask].columns)\n",
    "combined_mask = list(set(grs_parameters + gcs_parameters))\n",
    "df = df_working[combined_mask].copy()\n",
    "df['GRS_PREDICTIONS'] = grs_predictions\n",
    "df['GCS_PREDICTIONS'] = gcs_predictions\n",
    "knnr_model_bag = {\n",
    "    'df': df\n",
    "    ,'grs_model': grs_model\n",
    "    ,'grs_parameters': grs_parameters\n",
    "    ,'gcs_model': gcs_model\n",
    "    ,'gcs_parameters': gcs_parameters\n",
    "}\n",
    "with open('./app/knnr_model_bag.pkl','wb') as p:\n",
    "    pickle.dump(knnr_model_bag, p, protocol=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./app/knnr_model_bag.pkl','rb') as p:\n",
    "    bag = pickle.load(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grs_params = bag['grs_parameters']\n",
    "gcs_params = bag['gcs_parameters']\n",
    "all_params = list(set(grs_params + gcs_params))\n",
    "test_vec = bag['df'][all_params].sample(1).copy()\n",
    "# bag['grs_model'].predict(test_vec)\n",
    "# model = bag['grs_model']\n",
    "# list(model[:-1].get_feature_names_out())\n",
    "# print(*list(test_vec[grs_params].columns), sep='\\n,')\n",
    "gcs_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = test_vec.reset_index(drop=True).T\n",
    "vec.index.names = ['PARAMETERS']\n",
    "vec = vec.reset_index()\n",
    "vec.set_index('PARAMETERS').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag['grs_model'].predict(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the features scores rounded in 2 decimals\n",
    "pip_steps = grs_grid.best_estimator_.named_steps['kbest']\n",
    "pip_steps.get_support()\n",
    "\n",
    "features_scores = ['%.2f' % elem for elem in pip_steps.scores_ ]\n",
    "print(\"the features scores are \\n {}\".format(features_scores))\n",
    "\n",
    "feature_scores_pvalues = ['%.3f' % elem for elem in pip_steps.pvalues_]\n",
    "print(\"the feature_pvalues is \\n {} \".format(feature_scores_pvalues))\n",
    "\n",
    "scored_features = pd.DataFrame(df_working[grs_mask].columns, columns=['feature_names'])\n",
    "scored_features['feature_scores'] = features_scores\n",
    "scored_features['feature_scores_pvalues'] = feature_scores_pvalues\n",
    "scored_features = scored_features.loc[(scored_features['feature_scores'] != 'nan') & (scored_features['feature_scores'] != 'inf')].sort_values(by='feature_scores', ascending=False).iloc[:num_features]\n",
    "scored_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = scored_features.feature_names.to_list()\n",
    "df_working[selected_features].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(neigh, open('grs_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grs_model = pickle.load(open('grs_model.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(data_preds, open('grs_model.pkl','ab+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grs_data = []\n",
    "with open('./app/grs_model.pkl', 'rb') as fr:\n",
    "    try:\n",
    "        while True:\n",
    "            grs_data.append(pickle.load(fr))\n",
    "    except EOFError:\n",
    "        pass\n",
    "gcs_data = []\n",
    "with open('./app/gcs_model.pkl', 'rb') as fr:\n",
    "    try:\n",
    "        while True:\n",
    "            gcs_data.append(pickle.load(fr))\n",
    "    except EOFError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grs_model, grs_preds = grs_data\n",
    "gcs_model, gcs_preds = gcs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphWidth = 1500\n",
    "graphHeight = graphWidth * 800 / 1000\n",
    "x_plot = data_preds.DIRECT_COST\n",
    "y1_plot = data_preds.GRS_ACTUAL\n",
    "y2_plot = data_preds.GRS_PREDICTIONS\n",
    "f = plt.figure(figsize=(graphWidth/100.0, graphHeight/100.0), dpi=100)\n",
    "axes = f.add_subplot(111)\n",
    "axes.plot(x_plot, y1_plot, c='g', alpha=0.15)\n",
    "axes.plot(x_plot, y2_plot, alpha=0.15)\n",
    "axes.scatter(direct_cost, grs_cost, c='r', marker='D')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grs_fit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

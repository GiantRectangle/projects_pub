{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ootb per tpot settings (seems to return very different results when rerun with the same settings, which makes it hard to tell if tuning is working):\n",
    "\n",
    "    *  R2 for test grs data: 0.705872893854177\n",
    "    \n",
    "    *  negMedAE for test grs data: -2243.18338383248\n",
    "\n",
    "    *  R2 for test gcs data: 0.7512150347720993\n",
    "\n",
    "    *  negMedAE for test gcs data: -4511.080341844702"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import utils\n",
    "from os.path import join, dirname\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pickle\n",
    "from snowflake import connector\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RepeatedKFold\n",
    "from sklearn.preprocessing import Normalizer, QuantileTransformer, RobustScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tpot.export_utils import set_param_recursive\n",
    "from sklearn.metrics import r2_score, make_scorer\n",
    "\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "# get environment variables\n",
    "dotenv_path = join(dirname('streamlit_grs_fit\\\\app\\\\'), '.env')\n",
    "load_dotenv(dotenv_path)\n",
    "SF_ACCOUNT = os.getenv('SF_ACCOUNT')\n",
    "SF_USER = os.getenv('SF_USER')\n",
    "SF_PASSWORD = os.getenv('SF_PASSWORD')\n",
    "SF_ROLE = os.getenv('SF_ROLE')\n",
    "SF_WAREHOUSE = os.getenv('SF_WAREHOUSE')\n",
    "SF_DATABASE = os.getenv('SF_DATABASE')\n",
    "SF_SCHEMA = os.getenv('SF_SCHEMA')\n",
    "\n",
    "def load_data(query):\n",
    "    conn = connector.connect(\n",
    "        user = SF_USER\n",
    "        ,password = SF_PASSWORD\n",
    "        ,account = SF_ACCOUNT\n",
    "        ,warehouse = SF_WAREHOUSE\n",
    "        ,database = SF_DATABASE\n",
    "        ,schema = SF_SCHEMA\n",
    "        ,role = SF_ROLE\n",
    "    )\n",
    "    cur = conn.cursor()\n",
    "    df_data = cur.execute(query).fetch_pandas_all()\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'select '+\\\n",
    "            'JOB'+\\\n",
    "            ',DIRECT_COST'+\\\n",
    "            ',DIV_00_DIRECT_COST'+\\\n",
    "            ',DIV_01_DIRECT_COST'+\\\n",
    "            ',DIV_02_DIRECT_COST'+\\\n",
    "            ',DIV_03_DIRECT_COST'+\\\n",
    "            ',DIV_04_DIRECT_COST'+\\\n",
    "            ',DIV_05_DIRECT_COST'+\\\n",
    "            ',DIV_06_DIRECT_COST'+\\\n",
    "            ',DIV_07_DIRECT_COST'+\\\n",
    "            ',DIV_08_DIRECT_COST'+\\\n",
    "            ',DIV_09_DIRECT_COST'+\\\n",
    "            ',DIV_10_DIRECT_COST'+\\\n",
    "            ',DIV_11_DIRECT_COST'+\\\n",
    "            ',DIV_12_DIRECT_COST'+\\\n",
    "            ',DIV_13_DIRECT_COST'+\\\n",
    "            ',DIV_14_DIRECT_COST'+\\\n",
    "            ',DIV_15_DIRECT_COST'+\\\n",
    "            ',DIV_16_DIRECT_COST'+\\\n",
    "            ',DIV_17_DIRECT_COST'+\\\n",
    "            ',DIV_18_DIRECT_COST'+\\\n",
    "            ',DIV_19_DIRECT_COST'+\\\n",
    "            ',DIV_21_DIRECT_COST'+\\\n",
    "            ',DIV_22_DIRECT_COST'+\\\n",
    "            ',DIV_23_DIRECT_COST'+\\\n",
    "            ',DIV_26_DIRECT_COST'+\\\n",
    "            ',DIV_27_DIRECT_COST'+\\\n",
    "            ',DIV_28_DIRECT_COST'+\\\n",
    "            ',DIV_31_DIRECT_COST'+\\\n",
    "            ',DIV_32_DIRECT_COST'+\\\n",
    "            ',DIV_33_DIRECT_COST'+\\\n",
    "            ',DIV_34_DIRECT_COST'+\\\n",
    "            ',DIV_55_DIRECT_COST'+\\\n",
    "            ',GCS_COST'+\\\n",
    "            ',GRS_COST '+\\\n",
    "            'from sandbox.global.ml_grs_fit ' \n",
    "df_data = load_data(query).set_index('JOB') \n",
    "df_data = pd.DataFrame(df_data)\n",
    "df_data = df_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DIRECT_COST</th>\n",
       "      <th>DIV_00_DIRECT_COST</th>\n",
       "      <th>DIV_01_DIRECT_COST</th>\n",
       "      <th>DIV_02_DIRECT_COST</th>\n",
       "      <th>DIV_03_DIRECT_COST</th>\n",
       "      <th>DIV_04_DIRECT_COST</th>\n",
       "      <th>DIV_05_DIRECT_COST</th>\n",
       "      <th>DIV_06_DIRECT_COST</th>\n",
       "      <th>DIV_07_DIRECT_COST</th>\n",
       "      <th>DIV_08_DIRECT_COST</th>\n",
       "      <th>...</th>\n",
       "      <th>DIV_26_DIRECT_COST</th>\n",
       "      <th>DIV_27_DIRECT_COST</th>\n",
       "      <th>DIV_28_DIRECT_COST</th>\n",
       "      <th>DIV_31_DIRECT_COST</th>\n",
       "      <th>DIV_32_DIRECT_COST</th>\n",
       "      <th>DIV_33_DIRECT_COST</th>\n",
       "      <th>DIV_34_DIRECT_COST</th>\n",
       "      <th>DIV_55_DIRECT_COST</th>\n",
       "      <th>GCS_COST</th>\n",
       "      <th>GRS_COST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "      <td>3,332.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2,753,305.18</td>\n",
       "      <td>15,416.14</td>\n",
       "      <td>1,095.30</td>\n",
       "      <td>120,305.74</td>\n",
       "      <td>305,087.19</td>\n",
       "      <td>25,975.15</td>\n",
       "      <td>192,784.27</td>\n",
       "      <td>83,875.74</td>\n",
       "      <td>97,562.86</td>\n",
       "      <td>262,156.35</td>\n",
       "      <td>...</td>\n",
       "      <td>279,623.43</td>\n",
       "      <td>22,192.54</td>\n",
       "      <td>7,159.77</td>\n",
       "      <td>84,671.51</td>\n",
       "      <td>18,546.22</td>\n",
       "      <td>19,750.99</td>\n",
       "      <td>505.83</td>\n",
       "      <td>1,710.05</td>\n",
       "      <td>159,975.26</td>\n",
       "      <td>130,762.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18,205,353.59</td>\n",
       "      <td>247,803.94</td>\n",
       "      <td>21,856.71</td>\n",
       "      <td>835,518.53</td>\n",
       "      <td>2,456,075.21</td>\n",
       "      <td>255,679.11</td>\n",
       "      <td>1,926,522.10</td>\n",
       "      <td>479,208.15</td>\n",
       "      <td>712,596.43</td>\n",
       "      <td>2,347,850.24</td>\n",
       "      <td>...</td>\n",
       "      <td>2,283,423.57</td>\n",
       "      <td>355,302.65</td>\n",
       "      <td>98,050.42</td>\n",
       "      <td>852,341.42</td>\n",
       "      <td>200,217.24</td>\n",
       "      <td>315,920.99</td>\n",
       "      <td>14,397.44</td>\n",
       "      <td>98,425.42</td>\n",
       "      <td>991,159.86</td>\n",
       "      <td>893,014.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3,404,153.00</td>\n",
       "      <td>-327,264.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-41,282.56</td>\n",
       "      <td>-4,315,458.20</td>\n",
       "      <td>-164,664.12</td>\n",
       "      <td>-1,398,362.17</td>\n",
       "      <td>-174,550.72</td>\n",
       "      <td>-16,197.24</td>\n",
       "      <td>-407,656.41</td>\n",
       "      <td>...</td>\n",
       "      <td>-104.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-2,322.10</td>\n",
       "      <td>-11.50</td>\n",
       "      <td>-53,330.53</td>\n",
       "      <td>-4.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-3,335,087.00</td>\n",
       "      <td>-629,785.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4,410.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>554.25</td>\n",
       "      <td>305.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31,937.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>889.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>353.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>37.68</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4,763.00</td>\n",
       "      <td>2,099.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>279,720.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10,486.36</td>\n",
       "      <td>1,041.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>180.50</td>\n",
       "      <td>10,992.53</td>\n",
       "      <td>44.95</td>\n",
       "      <td>9,230.26</td>\n",
       "      <td>...</td>\n",
       "      <td>3,893.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35,369.50</td>\n",
       "      <td>16,783.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>399,570,438.00</td>\n",
       "      <td>8,618,727.16</td>\n",
       "      <td>762,087.69</td>\n",
       "      <td>26,715,320.64</td>\n",
       "      <td>49,560,386.64</td>\n",
       "      <td>9,635,075.36</td>\n",
       "      <td>51,850,542.49</td>\n",
       "      <td>9,711,287.61</td>\n",
       "      <td>19,337,427.69</td>\n",
       "      <td>56,887,683.67</td>\n",
       "      <td>...</td>\n",
       "      <td>57,604,860.12</td>\n",
       "      <td>14,904,687.98</td>\n",
       "      <td>2,706,150.04</td>\n",
       "      <td>19,786,153.90</td>\n",
       "      <td>6,898,015.60</td>\n",
       "      <td>10,785,799.69</td>\n",
       "      <td>607,500.00</td>\n",
       "      <td>5,681,453.04</td>\n",
       "      <td>23,749,853.00</td>\n",
       "      <td>18,182,714.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DIRECT_COST  DIV_00_DIRECT_COST  DIV_01_DIRECT_COST  \\\n",
       "count       3,332.00            3,332.00            3,332.00   \n",
       "mean    2,753,305.18           15,416.14            1,095.30   \n",
       "std    18,205,353.59          247,803.94           21,856.71   \n",
       "min    -3,404,153.00         -327,264.32                0.00   \n",
       "25%         4,410.75                0.00                0.00   \n",
       "50%        31,937.00                0.00                0.00   \n",
       "75%       279,720.25                0.00                0.00   \n",
       "max   399,570,438.00        8,618,727.16          762,087.69   \n",
       "\n",
       "       DIV_02_DIRECT_COST  DIV_03_DIRECT_COST  DIV_04_DIRECT_COST  \\\n",
       "count            3,332.00            3,332.00            3,332.00   \n",
       "mean           120,305.74          305,087.19           25,975.15   \n",
       "std            835,518.53        2,456,075.21          255,679.11   \n",
       "min            -41,282.56       -4,315,458.20         -164,664.12   \n",
       "25%                  0.00                0.00                0.00   \n",
       "50%                889.22                0.00                0.00   \n",
       "75%             10,486.36            1,041.34                0.00   \n",
       "max         26,715,320.64       49,560,386.64        9,635,075.36   \n",
       "\n",
       "       DIV_05_DIRECT_COST  DIV_06_DIRECT_COST  DIV_07_DIRECT_COST  \\\n",
       "count            3,332.00            3,332.00            3,332.00   \n",
       "mean           192,784.27           83,875.74           97,562.86   \n",
       "std          1,926,522.10          479,208.15          712,596.43   \n",
       "min         -1,398,362.17         -174,550.72          -16,197.24   \n",
       "25%                  0.00                0.00                0.00   \n",
       "50%                  0.00              353.55                0.00   \n",
       "75%                180.50           10,992.53               44.95   \n",
       "max         51,850,542.49        9,711,287.61       19,337,427.69   \n",
       "\n",
       "       DIV_08_DIRECT_COST  ...  DIV_26_DIRECT_COST  DIV_27_DIRECT_COST  \\\n",
       "count            3,332.00  ...            3,332.00            3,332.00   \n",
       "mean           262,156.35  ...          279,623.43           22,192.54   \n",
       "std          2,347,850.24  ...        2,283,423.57          355,302.65   \n",
       "min           -407,656.41  ...             -104.77                0.00   \n",
       "25%                  0.00  ...                0.00                0.00   \n",
       "50%                 37.68  ...                0.00                0.00   \n",
       "75%              9,230.26  ...            3,893.87                0.00   \n",
       "max         56,887,683.67  ...       57,604,860.12       14,904,687.98   \n",
       "\n",
       "       DIV_28_DIRECT_COST  DIV_31_DIRECT_COST  DIV_32_DIRECT_COST  \\\n",
       "count            3,332.00            3,332.00            3,332.00   \n",
       "mean             7,159.77           84,671.51           18,546.22   \n",
       "std             98,050.42          852,341.42          200,217.24   \n",
       "min                  0.00           -2,322.10              -11.50   \n",
       "25%                  0.00                0.00                0.00   \n",
       "50%                  0.00                0.00                0.00   \n",
       "75%                  0.00                0.00                0.00   \n",
       "max          2,706,150.04       19,786,153.90        6,898,015.60   \n",
       "\n",
       "       DIV_33_DIRECT_COST  DIV_34_DIRECT_COST  DIV_55_DIRECT_COST  \\\n",
       "count            3,332.00            3,332.00            3,332.00   \n",
       "mean            19,750.99              505.83            1,710.05   \n",
       "std            315,920.99           14,397.44           98,425.42   \n",
       "min            -53,330.53               -4.20                0.00   \n",
       "25%                  0.00                0.00                0.00   \n",
       "50%                  0.00                0.00                0.00   \n",
       "75%                  0.00                0.00                0.00   \n",
       "max         10,785,799.69          607,500.00        5,681,453.04   \n",
       "\n",
       "           GCS_COST      GRS_COST  \n",
       "count      3,332.00      3,332.00  \n",
       "mean     159,975.26    130,762.61  \n",
       "std      991,159.86    893,014.97  \n",
       "min   -3,335,087.00   -629,785.00  \n",
       "25%          554.25        305.75  \n",
       "50%        4,763.00      2,099.00  \n",
       "75%       35,369.50     16,783.00  \n",
       "max   23,749,853.00 18,182,714.00  \n",
       "\n",
       "[8 rows x 34 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_working = df_data.loc[\n",
    "                    (0 != df_data.GRS_COST) &\n",
    "                    (0 != df_data.GCS_COST)\n",
    "].copy()\n",
    "df_working.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3332,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X  = df_working.iloc[:,:-2] #.values\n",
    "y_gcs = df_working.iloc[:,-2:-1].values.ravel()\n",
    "y_grs = df_working.iloc[:,-1:].values.ravel()\n",
    "y_grs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_grs_train, y_grs_test = train_test_split(X, y_grs, test_size=0.33, random_state=42)\n",
    "X_train, X_test, y_gcs_train, y_gcs_test = train_test_split(X, y_gcs, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "\n",
    "# pipeline setup\n",
    "pipeline = Pipeline([\n",
    "                     ('scaler', None)\n",
    "                     ,('reg', GradientBoostingRegressor(min_samples_split=19, n_estimators=100, subsample=0.6500000000000001))\n",
    "                     ])\n",
    "\n",
    "parameters = {\n",
    "                # 'scaler':  [MinMaxScaler(), RobustScaler(), Normalizer(), QuantileTransformer()]\n",
    "                'scaler':  [MinMaxScaler(), QuantileTransformer()]\n",
    "                ,'reg__alpha':  [0.75]\n",
    "                ,'reg__learning_rate':  [0.01]\n",
    "                # ,'reg__learning_rate':  [0.0001, 0.001, 0.01, 0.1, 1.0] #this makes it worse\n",
    "                ,'reg__loss':  ['huber']\n",
    "                # ,'reg__max_depth':  [6]\n",
    "                ,'reg__max_depth':  [3, 6, 7, 9]\n",
    "                ,'reg__max_features':  [0.8]\n",
    "                ,'reg__min_samples_leaf':  [1]\n",
    "                ,'reg__min_samples_split':  [19]\n",
    "                ,'reg__n_estimators':  [100]\n",
    "                # ,'reg__n_estimators':  [10, 50, 100, 500]\n",
    "                ,'reg__subsample':  [0.6500000000000001]\n",
    "                # ,'reg__subsample':  [0.5, 0.6500000000000001, 0.7, 1.0]\n",
    "                }\n",
    "#grs model\n",
    "grs_grid = GridSearchCV(\n",
    "    pipeline\n",
    "    ,parameters\n",
    "    ,cv=cv\n",
    "    ,scoring={'R2': make_scorer(r2_score)\n",
    "            ,'negMedAE': make_scorer(utils.neg_median_absolute_error)\n",
    "    }\n",
    "    # ,refit='R2'\n",
    "    ,refit=utils.refit_strategy\n",
    "    ,return_train_score=False\n",
    "    ,n_jobs=-2\n",
    ")   \n",
    "\n",
    "#gcs model\n",
    "gcs_grid = GridSearchCV(\n",
    "    pipeline\n",
    "    ,parameters\n",
    "    ,cv=cv\n",
    "    ,scoring={'R2': make_scorer(r2_score)\n",
    "            ,'negMedAE': make_scorer(utils.neg_median_absolute_error)\n",
    "        }\n",
    "    ,refit=utils.refit_strategy\n",
    "    ,return_train_score=False\n",
    "    ,n_jobs=-2\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list({int(_) for _ in np.linspace(1, X.shape[1], X.shape[1])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All grid-search results:\n",
      "R2: 0.166 (±0.109), negMedAE: -1757.275 (±160.764), for {'reg__alpha': 0.75, 'reg__learning_rate': 0.01, 'reg__loss': 'huber', 'reg__max_depth': 3, 'reg__max_features': 0.8, 'reg__min_samples_leaf': 1, 'reg__min_samples_split': 19, 'reg__n_estimators': 100, 'reg__subsample': 0.6500000000000001, 'scaler': MinMaxScaler()}\n",
      "R2: 0.156 (±0.099), negMedAE: -1780.943 (±166.706), for {'reg__alpha': 0.75, 'reg__learning_rate': 0.01, 'reg__loss': 'huber', 'reg__max_depth': 3, 'reg__max_features': 0.8, 'reg__min_samples_leaf': 1, 'reg__min_samples_split': 19, 'reg__n_estimators': 100, 'reg__subsample': 0.6500000000000001, 'scaler': QuantileTransformer()}\n",
      "R2: 0.291 (±0.150), negMedAE: -1867.362 (±260.909), for {'reg__alpha': 0.75, 'reg__learning_rate': 0.01, 'reg__loss': 'huber', 'reg__max_depth': 6, 'reg__max_features': 0.8, 'reg__min_samples_leaf': 1, 'reg__min_samples_split': 19, 'reg__n_estimators': 100, 'reg__subsample': 0.6500000000000001, 'scaler': MinMaxScaler()}\n",
      "R2: 0.285 (±0.149), negMedAE: -1897.203 (±288.514), for {'reg__alpha': 0.75, 'reg__learning_rate': 0.01, 'reg__loss': 'huber', 'reg__max_depth': 6, 'reg__max_features': 0.8, 'reg__min_samples_leaf': 1, 'reg__min_samples_split': 19, 'reg__n_estimators': 100, 'reg__subsample': 0.6500000000000001, 'scaler': QuantileTransformer()}\n",
      "R2: 0.314 (±0.154), negMedAE: -1843.589 (±240.231), for {'reg__alpha': 0.75, 'reg__learning_rate': 0.01, 'reg__loss': 'huber', 'reg__max_depth': 7, 'reg__max_features': 0.8, 'reg__min_samples_leaf': 1, 'reg__min_samples_split': 19, 'reg__n_estimators': 100, 'reg__subsample': 0.6500000000000001, 'scaler': MinMaxScaler()}\n",
      "R2: 0.306 (±0.155), negMedAE: -1949.855 (±305.130), for {'reg__alpha': 0.75, 'reg__learning_rate': 0.01, 'reg__loss': 'huber', 'reg__max_depth': 7, 'reg__max_features': 0.8, 'reg__min_samples_leaf': 1, 'reg__min_samples_split': 19, 'reg__n_estimators': 100, 'reg__subsample': 0.6500000000000001, 'scaler': QuantileTransformer()}\n",
      "R2: 0.334 (±0.169), negMedAE: -1848.981 (±277.485), for {'reg__alpha': 0.75, 'reg__learning_rate': 0.01, 'reg__loss': 'huber', 'reg__max_depth': 9, 'reg__max_features': 0.8, 'reg__min_samples_leaf': 1, 'reg__min_samples_split': 19, 'reg__n_estimators': 100, 'reg__subsample': 0.6500000000000001, 'scaler': MinMaxScaler()}\n",
      "R2: 0.340 (±0.164), negMedAE: -1955.232 (±286.908), for {'reg__alpha': 0.75, 'reg__learning_rate': 0.01, 'reg__loss': 'huber', 'reg__max_depth': 9, 'reg__max_features': 0.8, 'reg__min_samples_leaf': 1, 'reg__min_samples_split': 19, 'reg__n_estimators': 100, 'reg__subsample': 0.6500000000000001, 'scaler': QuantileTransformer()}\n",
      "\n",
      "Models with an R2 higher than 0.23952013705534606:\n",
      "R2: 0.291 (±0.150), negMedAE: -1867.362 (±260.909), for {'reg__alpha': 0.75, 'reg__learning_rate': 0.01, 'reg__loss': 'huber', 'reg__max_depth': 6, 'reg__max_features': 0.8, 'reg__min_samples_leaf': 1, 'reg__min_samples_split': 19, 'reg__n_estimators': 100, 'reg__subsample': 0.6500000000000001, 'scaler': MinMaxScaler()}\n",
      "R2: 0.285 (±0.149), negMedAE: -1897.203 (±288.514), for {'reg__alpha': 0.75, 'reg__learning_rate': 0.01, 'reg__loss': 'huber', 'reg__max_depth': 6, 'reg__max_features': 0.8, 'reg__min_samples_leaf': 1, 'reg__min_samples_split': 19, 'reg__n_estimators': 100, 'reg__subsample': 0.6500000000000001, 'scaler': QuantileTransformer()}\n",
      "R2: 0.314 (±0.154), negMedAE: -1843.589 (±240.231), for {'reg__alpha': 0.75, 'reg__learning_rate': 0.01, 'reg__loss': 'huber', 'reg__max_depth': 7, 'reg__max_features': 0.8, 'reg__min_samples_leaf': 1, 'reg__min_samples_split': 19, 'reg__n_estimators': 100, 'reg__subsample': 0.6500000000000001, 'scaler': MinMaxScaler()}\n",
      "R2: 0.306 (±0.155), negMedAE: -1949.855 (±305.130), for {'reg__alpha': 0.75, 'reg__learning_rate': 0.01, 'reg__loss': 'huber', 'reg__max_depth': 7, 'reg__max_features': 0.8, 'reg__min_samples_leaf': 1, 'reg__min_samples_split': 19, 'reg__n_estimators': 100, 'reg__subsample': 0.6500000000000001, 'scaler': QuantileTransformer()}\n",
      "R2: 0.334 (±0.169), negMedAE: -1848.981 (±277.485), for {'reg__alpha': 0.75, 'reg__learning_rate': 0.01, 'reg__loss': 'huber', 'reg__max_depth': 9, 'reg__max_features': 0.8, 'reg__min_samples_leaf': 1, 'reg__min_samples_split': 19, 'reg__n_estimators': 100, 'reg__subsample': 0.6500000000000001, 'scaler': MinMaxScaler()}\n",
      "R2: 0.340 (±0.164), negMedAE: -1955.232 (±286.908), for {'reg__alpha': 0.75, 'reg__learning_rate': 0.01, 'reg__loss': 'huber', 'reg__max_depth': 9, 'reg__max_features': 0.8, 'reg__min_samples_leaf': 1, 'reg__min_samples_split': 19, 'reg__n_estimators': 100, 'reg__subsample': 0.6500000000000001, 'scaler': QuantileTransformer()}\n",
      "\n",
      "\n",
      "The selected final model is the best negMedAE out of the previously\n",
      "selected subset of best models based on R2 - 0.1.\n",
      "Its details are:\n",
      "\n",
      "mean_score_time                                                    0.01\n",
      "mean_test_R2                                                       0.31\n",
      "std_test_R2                                                        0.15\n",
      "mean_test_negMedAE                                            -1,843.59\n",
      "std_test_negMedAE                                                240.23\n",
      "rank_test_R2                                                          3\n",
      "rank_test_negMedAE                                                    3\n",
      "params                {'reg__alpha': 0.75, 'reg__learning_rate': 0.0...\n",
      "Name: 4, dtype: object\n"
     ]
    }
   ],
   "source": [
    "grs_grid = grs_grid.fit(X_train, y_grs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All grid-search results:\n",
      "R2: 0.244 (±0.137), negMedAE: -3499.760 (±441.367), for {'reg__alpha': 0.75, 'reg__learning_rate': 0.01, 'reg__loss': 'huber', 'reg__max_depth': 6, 'reg__max_features': 0.8, 'reg__min_samples_leaf': 1, 'reg__min_samples_split': 19, 'reg__n_estimators': 100, 'reg__subsample': 0.6500000000000001, 'scaler': MinMaxScaler()}\n",
      "R2: 0.244 (±0.134), negMedAE: -3574.778 (±505.361), for {'reg__alpha': 0.75, 'reg__learning_rate': 0.01, 'reg__loss': 'huber', 'reg__max_depth': 6, 'reg__max_features': 0.8, 'reg__min_samples_leaf': 1, 'reg__min_samples_split': 19, 'reg__n_estimators': 100, 'reg__subsample': 0.6500000000000001, 'scaler': QuantileTransformer()}\n",
      "\n",
      "Models with an R2 higher than 0.14448255148466965:\n",
      "R2: 0.244 (±0.137), negMedAE: -3499.760 (±441.367), for {'reg__alpha': 0.75, 'reg__learning_rate': 0.01, 'reg__loss': 'huber', 'reg__max_depth': 6, 'reg__max_features': 0.8, 'reg__min_samples_leaf': 1, 'reg__min_samples_split': 19, 'reg__n_estimators': 100, 'reg__subsample': 0.6500000000000001, 'scaler': MinMaxScaler()}\n",
      "R2: 0.244 (±0.134), negMedAE: -3574.778 (±505.361), for {'reg__alpha': 0.75, 'reg__learning_rate': 0.01, 'reg__loss': 'huber', 'reg__max_depth': 6, 'reg__max_features': 0.8, 'reg__min_samples_leaf': 1, 'reg__min_samples_split': 19, 'reg__n_estimators': 100, 'reg__subsample': 0.6500000000000001, 'scaler': QuantileTransformer()}\n",
      "\n",
      "\n",
      "The selected final model is the best negMedAE out of the previously\n",
      "selected subset of best models based on R2 - 0.1.\n",
      "Its details are:\n",
      "\n",
      "mean_score_time                                                    0.00\n",
      "mean_test_R2                                                       0.24\n",
      "std_test_R2                                                        0.14\n",
      "mean_test_negMedAE                                            -3,499.76\n",
      "std_test_negMedAE                                                441.37\n",
      "rank_test_R2                                                          1\n",
      "rank_test_negMedAE                                                    1\n",
      "params                {'reg__alpha': 0.75, 'reg__learning_rate': 0.0...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "gcs_grid = gcs_grid.fit(X_train, y_gcs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for test grs data: 0.29795144973329835\n",
      "negMedAE for test grs data: -2201.306725798465\n"
     ]
    }
   ],
   "source": [
    "y_grs_test_pred = grs_grid.best_estimator_.predict(X_test)\n",
    "print(f'R2 for test grs data: {r2_score(y_grs_test, y_grs_test_pred)}')\n",
    "print(f'negMedAE for test grs data: {utils.neg_median_absolute_error(y_grs_test, y_grs_test_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for test gcs data: 0.20663506955134714\n",
      "negMedAE for test gcs data: -4294.055925788829\n"
     ]
    }
   ],
   "source": [
    "y_gcs_test_pred = gcs_grid.best_estimator_.predict(X_test)\n",
    "print(f'R2 for test gcs data: {r2_score(y_gcs_test, y_gcs_test_pred)}')\n",
    "print(f'negMedAE for test gcs data: {utils.neg_median_absolute_error(y_gcs_test, y_gcs_test_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_grid_test = gcs_grid.best_estimator_.fit(X_test, y_gcs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best grs estimator is \n",
      " Pipeline(steps=[('scaler', QuantileTransformer()), ('kbest', SelectKBest(k=28)),\n",
      "                ('reg',\n",
      "                 GradientBoostingRegressor(alpha=0.75, loss='huber',\n",
      "                                           max_depth=6, max_features=0.8,\n",
      "                                           min_samples_split=19,\n",
      "                                           subsample=0.6500000000000001))]) \n",
      "the best grs parameters are \n",
      " {'kbest__k': 28, 'reg__alpha': 0.75, 'reg__learning_rate': 0.1, 'reg__loss': 'huber', 'reg__max_depth': 6, 'reg__max_features': 0.8, 'reg__min_samples_leaf': 1, 'reg__min_samples_split': 19, 'reg__n_estimators': 100, 'reg__subsample': 0.6500000000000001, 'scaler': QuantileTransformer()}\n",
      "the best gcs estimator is \n",
      " Pipeline(steps=[('scaler', MinMaxScaler()), ('kbest', SelectKBest(k=25)),\n",
      "                ('reg',\n",
      "                 GradientBoostingRegressor(alpha=0.75, loss='huber',\n",
      "                                           max_depth=6, max_features=0.8,\n",
      "                                           min_samples_split=19,\n",
      "                                           subsample=0.6500000000000001))]) \n",
      "the best gcs parameters are \n",
      " {'kbest__k': 25, 'reg__alpha': 0.75, 'reg__learning_rate': 0.1, 'reg__loss': 'huber', 'reg__max_depth': 6, 'reg__max_features': 0.8, 'reg__min_samples_leaf': 1, 'reg__min_samples_split': 19, 'reg__n_estimators': 100, 'reg__subsample': 0.6500000000000001, 'scaler': MinMaxScaler()}\n"
     ]
    }
   ],
   "source": [
    "print(\"the best grs estimator is \\n {} \".format(grs_grid.best_estimator_))\n",
    "print(\"the best grs parameters are \\n {}\".format(grs_grid.best_params_))\n",
    "print(\"the best gcs estimator is \\n {} \".format(gcs_grid.best_estimator_))\n",
    "print(\"the best gcs parameters are \\n {}\".format(gcs_grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grs_best_pipe = grs_grid.best_estimator_\n",
    "grs_mask = list(grs_best_pipe.fit(X,y_grs)[:-1].get_feature_names_out())\n",
    "grs_model = grs_best_pipe.fit(df_working[grs_mask],y_grs)\n",
    "grs_predictions = grs_model.predict(df_working[grs_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_best_pipe = gcs_grid.best_estimator_\n",
    "gcs_mask = list(gcs_best_pipe.fit(X,y_gcs)[:-1].get_feature_names_out())\n",
    "gcs_model = gcs_best_pipe.fit(df_working[gcs_mask],y_gcs)\n",
    "gcs_predictions = gcs_model.predict(df_working[gcs_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(grs_model[:-1].get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grs_parameters = list(df_working[grs_mask].columns)\n",
    "gcs_parameters = list(df_working[gcs_mask].columns)\n",
    "combined_mask = list(set(grs_parameters + gcs_parameters))\n",
    "df = df_working[combined_mask].copy()\n",
    "df['GRS_PREDICTIONS'] = grs_predictions\n",
    "df['GCS_PREDICTIONS'] = gcs_predictions\n",
    "knnr_model_bag = {\n",
    "    'df': df\n",
    "    ,'grs_model': grs_model\n",
    "    ,'grs_parameters': grs_parameters\n",
    "    ,'gcs_model': gcs_model\n",
    "    ,'gcs_parameters': gcs_parameters\n",
    "}\n",
    "with open('./app/knnr_model_bag.pkl','wb') as p:\n",
    "    pickle.dump(knnr_model_bag, p, protocol=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./app/model_bag.pkl','rb') as p:\n",
    "    bag = pickle.load(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grs_params = bag['grs_parameters']\n",
    "gcs_params = bag['gcs_parameters']\n",
    "all_params = list(set(grs_params + gcs_params))\n",
    "test_vec = bag['df'][all_params].sample(1).copy()\n",
    "# bag['grs_model'].predict(test_vec)\n",
    "# model = bag['grs_model']\n",
    "# list(model[:-1].get_feature_names_out())\n",
    "print(*list(test_vec[grs_params].columns), sep='\\n,')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = test_vec.reset_index(drop=True).T\n",
    "vec.index.names = ['PARAMETERS']\n",
    "vec = vec.reset_index()\n",
    "vec.set_index('PARAMETERS').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag['grs_model'].predict(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the features scores rounded in 2 decimals\n",
    "pip_steps = grs_grid.best_estimator_.named_steps['kbest']\n",
    "pip_steps.get_support()\n",
    "\n",
    "features_scores = ['%.2f' % elem for elem in pip_steps.scores_ ]\n",
    "print(\"the features scores are \\n {}\".format(features_scores))\n",
    "\n",
    "feature_scores_pvalues = ['%.3f' % elem for elem in pip_steps.pvalues_]\n",
    "print(\"the feature_pvalues is \\n {} \".format(feature_scores_pvalues))\n",
    "\n",
    "scored_features = pd.DataFrame(df_working[grs_mask].columns, columns=['feature_names'])\n",
    "scored_features['feature_scores'] = features_scores\n",
    "scored_features['feature_scores_pvalues'] = feature_scores_pvalues\n",
    "scored_features = scored_features.loc[(scored_features['feature_scores'] != 'nan') & (scored_features['feature_scores'] != 'inf')].sort_values(by='feature_scores', ascending=False).iloc[:num_features]\n",
    "scored_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = scored_features.feature_names.to_list()\n",
    "df_working[selected_features].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(neigh, open('grs_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grs_model = pickle.load(open('grs_model.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(data_preds, open('grs_model.pkl','ab+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grs_data = []\n",
    "with open('./app/grs_model.pkl', 'rb') as fr:\n",
    "    try:\n",
    "        while True:\n",
    "            grs_data.append(pickle.load(fr))\n",
    "    except EOFError:\n",
    "        pass\n",
    "gcs_data = []\n",
    "with open('./app/gcs_model.pkl', 'rb') as fr:\n",
    "    try:\n",
    "        while True:\n",
    "            gcs_data.append(pickle.load(fr))\n",
    "    except EOFError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grs_model, grs_preds = grs_data\n",
    "gcs_model, gcs_preds = gcs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphWidth = 1500\n",
    "graphHeight = graphWidth * 800 / 1000\n",
    "x_plot = data_preds.DIRECT_COST\n",
    "y1_plot = data_preds.GRS_ACTUAL\n",
    "y2_plot = data_preds.GRS_PREDICTIONS\n",
    "f = plt.figure(figsize=(graphWidth/100.0, graphHeight/100.0), dpi=100)\n",
    "axes = f.add_subplot(111)\n",
    "axes.plot(x_plot, y1_plot, c='g', alpha=0.15)\n",
    "axes.plot(x_plot, y2_plot, alpha=0.15)\n",
    "axes.scatter(direct_cost, grs_cost, c='r', marker='D')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grs_fit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
